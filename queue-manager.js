/**
 * ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨
 * ä½¿ç”¨ Bull (åŸºäº Redis) å®ç°å¼‚æ­¥ä»»åŠ¡å¤„ç†
 *
 * åŠŸèƒ½ï¼š
 * - å›¾ç‰‡ä¸Šä¼ å¤„ç†é˜Ÿåˆ—
 * - æ•°æ®åº“å¤‡ä»½/æ¢å¤é˜Ÿåˆ—
 * - å­˜å‚¨è¿ç§»é˜Ÿåˆ—
 * - ä»»åŠ¡è¿›åº¦è¿½è¸ª
 */

const Queue = require('bull');
const sharp = require('sharp');
const fs = require('fs');
const path = require('path');
const pLimit = require('p-limit');

class QueueManager {
  constructor(redisClient, imageDb, config) {
    this.redisClient = redisClient;
    this.imageDb = imageDb;
    this.config = config;
    this.queues = {};
    this.initialized = false;
  }

  /**
   * åˆå§‹åŒ–æ‰€æœ‰é˜Ÿåˆ—
   */
  async initialize() {
    if (this.initialized) {
      console.log('âš ï¸  é˜Ÿåˆ—ç®¡ç†å™¨å·²åˆå§‹åŒ–');
      return;
    }

    try {
      // è·å– Redis é…ç½®
      const redisConfig = {
        host: process.env.REDIS_HOST || '127.0.0.1',
        port: parseInt(process.env.REDIS_PORT || '6379'),
        password: process.env.REDIS_PASSWORD || undefined,
        db: parseInt(process.env.REDIS_DB || '0'),
        retryStrategy: (times) => {
          const delay = Math.min(times * 50, 2000);
          return delay;
        }
      };

      // åˆ›å»ºå›¾ç‰‡å¤„ç†é˜Ÿåˆ—
      this.queues.imageProcessing = new Queue('image-processing', {
        redis: redisConfig,
        defaultJobOptions: {
          attempts: 3, // å¤±è´¥é‡è¯• 3 æ¬¡
          backoff: {
            type: 'exponential',
            delay: 2000 // 2ç§’åé‡è¯•
          },
          removeOnComplete: 100, // ä¿ç•™æœ€è¿‘ 100 ä¸ªå®Œæˆçš„ä»»åŠ¡
          removeOnFail: 200 // ä¿ç•™æœ€è¿‘ 200 ä¸ªå¤±è´¥çš„ä»»åŠ¡
        }
      });

      // åˆ›å»ºæ•°æ®åº“å¤‡ä»½é˜Ÿåˆ—
      this.queues.databaseBackup = new Queue('database-backup', {
        redis: redisConfig,
        defaultJobOptions: {
          attempts: 2,
          timeout: 600000, // 10 åˆ†é’Ÿè¶…æ—¶
          removeOnComplete: 50
        }
      });

      // åˆ›å»ºå­˜å‚¨è¿ç§»é˜Ÿåˆ—
      this.queues.storageMigration = new Queue('storage-migration', {
        redis: redisConfig,
        defaultJobOptions: {
          attempts: 1,
          timeout: 1800000, // 30 åˆ†é’Ÿè¶…æ—¶
          removeOnComplete: 10
        }
      });

      // æ³¨å†Œå¤„ç†å™¨
      this.registerProcessors();

      // æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
      this.registerEventListeners();

      this.initialized = true;
      console.log('âœ… ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ');
    } catch (error) {
      console.error('âŒ ä»»åŠ¡é˜Ÿåˆ—åˆå§‹åŒ–å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * æ³¨å†Œä»»åŠ¡å¤„ç†å™¨
   */
  registerProcessors() {
    // å›¾ç‰‡å¤„ç†å™¨ï¼ˆæ”¯æŒå¹¶å‘ï¼‰
    this.queues.imageProcessing.process('upload', 5, async (job) => {
      return await this.processImageUpload(job);
    });

    // æ‰¹é‡å›¾ç‰‡å¤„ç†å™¨
    this.queues.imageProcessing.process('batch-upload', 1, async (job) => {
      return await this.processBatchImageUpload(job);
    });

    // æ•°æ®åº“å¤‡ä»½å¤„ç†å™¨
    this.queues.databaseBackup.process('backup', async (job) => {
      return await this.processDatabaseBackup(job);
    });

    // æ•°æ®åº“æ¢å¤å¤„ç†å™¨
    this.queues.databaseBackup.process('restore', async (job) => {
      return await this.processDatabaseRestore(job);
    });

    // å­˜å‚¨è¿ç§»å¤„ç†å™¨
    this.queues.storageMigration.process('migrate', async (job) => {
      return await this.processStorageMigration(job);
    });
  }

  /**
   * æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
   */
  registerEventListeners() {
    Object.entries(this.queues).forEach(([name, queue]) => {
      queue.on('completed', (job, result) => {
        console.log(`âœ… [${name}] ä»»åŠ¡å®Œæˆ: ${job.id}`, {
          duration: Date.now() - job.timestamp,
          result: result?.message || 'success'
        });
      });

      queue.on('failed', (job, err) => {
        console.error(`âŒ [${name}] ä»»åŠ¡å¤±è´¥: ${job.id}`, {
          error: err.message,
          attempts: job.attemptsMade
        });
      });

      queue.on('stalled', (job) => {
        console.warn(`âš ï¸  [${name}] ä»»åŠ¡åœæ»: ${job.id}`);
      });
    });
  }

  /**
   * å¤„ç†å•å¼ å›¾ç‰‡ä¸Šä¼ 
   */
  async processImageUpload(job) {
    const { fileData, options, userId } = job.data;
    const startTime = Date.now();

    try {
      // æ›´æ–°è¿›åº¦: å¼€å§‹å¤„ç†
      await job.progress(10);

      // è§£ææ–‡ä»¶ç¼“å†²åŒº
      const fileBuffer = Buffer.from(fileData.buffer, 'base64');
      const originalName = fileData.originalname;
      const filename = `${Date.now()}-${Math.random().toString(36).substring(7)}.webp`;

      // æ›´æ–°è¿›åº¦: å›¾ç‰‡ä¼˜åŒ–
      await job.progress(30);

      // Sharp å›¾ç‰‡å¤„ç†
      const quality = parseInt(options.quality || process.env.IMAGE_QUALITY_WEBP || 80);
      const optimizedBuffer = await sharp(fileBuffer)
        .toFormat('webp', { quality })
        .toBuffer();

      // æ›´æ–°è¿›åº¦: ä¸Šä¼ å­˜å‚¨
      await job.progress(60);

      // æ ¹æ®å­˜å‚¨ç±»å‹å¤„ç†
      let imageUrl, imagePath;
      if (options.storageType === 'r2' && options.r2Config) {
        // R2 äº‘å­˜å‚¨
        const r2Path = `images/${filename}`;
        imageUrl = await this.uploadToR2(optimizedBuffer, r2Path, options.r2Config);
        imagePath = r2Path;
      } else {
        // æœ¬åœ°å­˜å‚¨
        const uploadDir = path.join(process.cwd(), 'uploads');
        if (!fs.existsSync(uploadDir)) {
          fs.mkdirSync(uploadDir, { recursive: true });
        }
        imagePath = path.join('uploads', filename);
        const fullPath = path.join(process.cwd(), imagePath);
        fs.writeFileSync(fullPath, optimizedBuffer);

        // ç”Ÿæˆ URL
        const domain = options.imageDomain || options.currentDomain;
        imageUrl = `${domain}/i/${filename}`;
      }

      // æ›´æ–°è¿›åº¦: ä¿å­˜æ•°æ®åº“
      await job.progress(80);

      // ç”Ÿæˆ Markdown å’Œ HTML ä»£ç 
      const markdownCode = `![${originalName}](${imageUrl})`;
      const htmlCode = `<img src="${imageUrl}" alt="${originalName}" />`;

      // ä¿å­˜åˆ°æ•°æ®åº“
      const imageData = {
        filename,
        path: imagePath,
        upload_time: new Date(),
        file_size: optimizedBuffer.length,
        storage: options.storageType || 'local',
        format: 'webp',
        url: imageUrl,
        html_code: htmlCode,
        markdown_code: markdownCode,
        category_id: options.categoryId || null
      };

      await this.imageDb.addImage(imageData);

      // æ¸…é™¤ç¼“å­˜
      if (this.redisClient?.connected) {
        await this.redisClient.del('cache:images:all');
        await this.redisClient.del('cache:stats');
      }

      // æ›´æ–°è¿›åº¦: å®Œæˆ
      await job.progress(100);

      const duration = Date.now() - startTime;
      return {
        success: true,
        filename,
        url: imageUrl,
        markdown: markdownCode,
        html: htmlCode,
        size: optimizedBuffer.length,
        duration
      };

    } catch (error) {
      console.error('å›¾ç‰‡å¤„ç†å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†æ‰¹é‡å›¾ç‰‡ä¸Šä¼ ï¼ˆå¹¶è¡Œä¼˜åŒ–ï¼‰
   */
  async processBatchImageUpload(job) {
    const { files, options, userId } = job.data;
    const startTime = Date.now();
    const results = [];
    const errors = [];

    try {
      // å¹¶å‘é™åˆ¶ï¼ˆåŒæ—¶å¤„ç† 5 å¼ å›¾ç‰‡ï¼‰
      const limit = pLimit(5);

      const tasks = files.map((fileData, index) =>
        limit(async () => {
          try {
            // ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå­ä»»åŠ¡
            const subJob = await this.queues.imageProcessing.add('upload', {
              fileData,
              options,
              userId
            }, {
              priority: 1 // ä¼˜å…ˆçº§
            });

            // ç­‰å¾…å­ä»»åŠ¡å®Œæˆ
            const result = await subJob.finished();
            results.push(result);

            // æ›´æ–°æ‰¹é‡ä»»åŠ¡è¿›åº¦
            const progress = Math.floor(((index + 1) / files.length) * 100);
            await job.progress(progress);

            return result;
          } catch (error) {
            errors.push({
              filename: fileData.originalname,
              error: error.message
            });
            return null;
          }
        })
      );

      await Promise.all(tasks);

      const duration = Date.now() - startTime;
      const successCount = results.filter(r => r !== null).length;

      return {
        success: true,
        total: files.length,
        successCount,
        failCount: errors.length,
        results: results.filter(r => r !== null),
        errors,
        duration
      };

    } catch (error) {
      console.error('æ‰¹é‡å›¾ç‰‡å¤„ç†å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†æ•°æ®åº“å¤‡ä»½
   */
  async processDatabaseBackup(job) {
    const { format } = job.data;

    try {
      await job.progress(10);

      let result;
      if (format === 'sql') {
        await job.progress(30);
        result = await this.imageDb.exportToSql();
      } else {
        await job.progress(30);
        result = await this.imageDb.exportToJson();
      }

      await job.progress(100);

      return {
        success: true,
        format,
        path: result.path,
        message: result.message
      };

    } catch (error) {
      console.error('æ•°æ®åº“å¤‡ä»½å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†æ•°æ®åº“æ¢å¤
   */
  async processDatabaseRestore(job) {
    const { filePath, format } = job.data;

    try {
      await job.progress(10);

      let result;
      if (format === 'sql') {
        await job.progress(30);
        result = await this.imageDb.importFromSql(filePath);
      } else {
        await job.progress(30);
        result = await this.imageDb.importFromJson(filePath);
      }

      await job.progress(100);

      return {
        success: true,
        format,
        message: result.message || 'æ¢å¤æˆåŠŸ'
      };

    } catch (error) {
      console.error('æ•°æ®åº“æ¢å¤å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†å­˜å‚¨è¿ç§»
   */
  async processStorageMigration(job) {
    const { fromStorage, toStorage, options } = job.data;

    try {
      await job.progress(5);

      // è·å–éœ€è¦è¿ç§»çš„å›¾ç‰‡åˆ—è¡¨
      const images = await this.imageDb.getImagesByStorage(fromStorage);
      const total = images.length;
      let migrated = 0;
      let failed = 0;

      await job.progress(10);

      // å¹¶å‘é™åˆ¶ï¼ˆåŒæ—¶å¤„ç† 3 å¼ å›¾ç‰‡ï¼‰
      const limit = pLimit(3);

      const tasks = images.map((image, index) =>
        limit(async () => {
          try {
            // è¯»å–æºæ–‡ä»¶
            let fileBuffer;
            if (fromStorage === 'local') {
              const fullPath = path.join(process.cwd(), image.path);
              fileBuffer = fs.readFileSync(fullPath);
            } else {
              // ä» R2 ä¸‹è½½ï¼ˆéœ€è¦å®ç°ï¼‰
              fileBuffer = await this.downloadFromR2(image.path, options.r2Config);
            }

            // ä¸Šä¼ åˆ°ç›®æ ‡å­˜å‚¨
            let newUrl, newPath;
            if (toStorage === 'r2') {
              const r2Path = `images/${path.basename(image.path)}`;
              newUrl = await this.uploadToR2(fileBuffer, r2Path, options.r2Config);
              newPath = r2Path;
            } else {
              const uploadDir = path.join(process.cwd(), 'uploads');
              if (!fs.existsSync(uploadDir)) {
                fs.mkdirSync(uploadDir, { recursive: true });
              }
              newPath = path.join('uploads', path.basename(image.path));
              const fullPath = path.join(process.cwd(), newPath);
              fs.writeFileSync(fullPath, fileBuffer);

              const domain = options.imageDomain || options.currentDomain;
              newUrl = `${domain}/i/${path.basename(image.path)}`;
            }

            // æ›´æ–°æ•°æ®åº“
            await this.imageDb.updateImageStorage(image.id, {
              storage: toStorage,
              path: newPath,
              url: newUrl
            });

            migrated++;

            // æ›´æ–°è¿›åº¦
            const progress = Math.floor(10 + ((index + 1) / total) * 85);
            await job.progress(progress);

          } catch (error) {
            console.error(`è¿ç§»å›¾ç‰‡ ${image.filename} å¤±è´¥:`, error);
            failed++;
          }
        })
      );

      await Promise.all(tasks);

      await job.progress(100);

      return {
        success: true,
        total,
        migrated,
        failed,
        message: `è¿ç§»å®Œæˆ: ${migrated}/${total} æˆåŠŸ, ${failed} å¤±è´¥`
      };

    } catch (error) {
      console.error('å­˜å‚¨è¿ç§»å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * ä¸Šä¼ æ–‡ä»¶åˆ° R2
   */
  async uploadToR2(buffer, key, r2Config) {
    const { S3Client, PutObjectCommand } = require('@aws-sdk/client-s3');

    const s3Client = new S3Client({
      region: r2Config.region || 'auto',
      endpoint: r2Config.endpoint,
      credentials: {
        accessKeyId: r2Config.accessKeyId,
        secretAccessKey: r2Config.secretAccessKey
      }
    });

    const command = new PutObjectCommand({
      Bucket: r2Config.bucket,
      Key: key,
      Body: buffer,
      ContentType: 'image/webp'
    });

    await s3Client.send(command);

    // è¿”å› URL
    if (r2Config.customDomain) {
      return `${r2Config.customDomain}/${key}`;
    } else {
      return `${r2Config.endpoint}/${r2Config.bucket}/${key}`;
    }
  }

  /**
   * ä» R2 ä¸‹è½½æ–‡ä»¶
   */
  async downloadFromR2(key, r2Config) {
    const { S3Client, GetObjectCommand } = require('@aws-sdk/client-s3');

    const s3Client = new S3Client({
      region: r2Config.region || 'auto',
      endpoint: r2Config.endpoint,
      credentials: {
        accessKeyId: r2Config.accessKeyId,
        secretAccessKey: r2Config.secretAccessKey
      }
    });

    const command = new GetObjectCommand({
      Bucket: r2Config.bucket,
      Key: key
    });

    const response = await s3Client.send(command);
    const chunks = [];

    for await (const chunk of response.Body) {
      chunks.push(chunk);
    }

    return Buffer.concat(chunks);
  }

  /**
   * æ·»åŠ å›¾ç‰‡å¤„ç†ä»»åŠ¡
   */
  async addImageUploadJob(fileData, options, userId = null) {
    const job = await this.queues.imageProcessing.add('upload', {
      fileData,
      options,
      userId
    }, {
      priority: 2
    });

    return {
      jobId: job.id,
      queue: 'image-processing'
    };
  }

  /**
   * æ·»åŠ æ‰¹é‡å›¾ç‰‡å¤„ç†ä»»åŠ¡
   */
  async addBatchImageUploadJob(files, options, userId = null) {
    const job = await this.queues.imageProcessing.add('batch-upload', {
      files,
      options,
      userId
    }, {
      priority: 1
    });

    return {
      jobId: job.id,
      queue: 'image-processing'
    };
  }

  /**
   * æ·»åŠ å¤‡ä»½ä»»åŠ¡
   */
  async addBackupJob(format = 'sql') {
    const job = await this.queues.databaseBackup.add('backup', {
      format
    });

    return {
      jobId: job.id,
      queue: 'database-backup'
    };
  }

  /**
   * æ·»åŠ æ¢å¤ä»»åŠ¡
   */
  async addRestoreJob(filePath, format = 'sql') {
    const job = await this.queues.databaseBackup.add('restore', {
      filePath,
      format
    });

    return {
      jobId: job.id,
      queue: 'database-backup'
    };
  }

  /**
   * æ·»åŠ å­˜å‚¨è¿ç§»ä»»åŠ¡
   */
  async addMigrationJob(fromStorage, toStorage, options) {
    const job = await this.queues.storageMigration.add('migrate', {
      fromStorage,
      toStorage,
      options
    });

    return {
      jobId: job.id,
      queue: 'storage-migration'
    };
  }

  /**
   * è·å–ä»»åŠ¡çŠ¶æ€
   */
  async getJobStatus(queueName, jobId) {
    const queue = this.queues[queueName];
    if (!queue) {
      throw new Error(`é˜Ÿåˆ—ä¸å­˜åœ¨: ${queueName}`);
    }

    const job = await queue.getJob(jobId);
    if (!job) {
      return {
        exists: false,
        message: 'ä»»åŠ¡ä¸å­˜åœ¨'
      };
    }

    const state = await job.getState();
    const progress = job.progress();
    const result = job.returnvalue;
    const failedReason = job.failedReason;

    return {
      exists: true,
      jobId: job.id,
      state,
      progress,
      result,
      failedReason,
      attemptsMade: job.attemptsMade,
      timestamp: job.timestamp
    };
  }

  /**
   * è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
   */
  async getQueueStats(queueName) {
    const queue = this.queues[queueName];
    if (!queue) {
      throw new Error(`é˜Ÿåˆ—ä¸å­˜åœ¨: ${queueName}`);
    }

    const [waiting, active, completed, failed, delayed] = await Promise.all([
      queue.getWaitingCount(),
      queue.getActiveCount(),
      queue.getCompletedCount(),
      queue.getFailedCount(),
      queue.getDelayedCount()
    ]);

    return {
      waiting,
      active,
      completed,
      failed,
      delayed,
      total: waiting + active + completed + failed + delayed
    };
  }

  /**
   * æ¸…ç†é˜Ÿåˆ—
   */
  async cleanQueue(queueName, grace = 0, type = 'completed') {
    const queue = this.queues[queueName];
    if (!queue) {
      throw new Error(`é˜Ÿåˆ—ä¸å­˜åœ¨: ${queueName}`);
    }

    await queue.clean(grace, type);
    return {
      success: true,
      message: `é˜Ÿåˆ— ${queueName} çš„ ${type} ä»»åŠ¡å·²æ¸…ç†`
    };
  }

  /**
   * å…³é—­æ‰€æœ‰é˜Ÿåˆ—
   */
  async shutdown() {
    console.log('ğŸ”„ æ­£åœ¨å…³é—­ä»»åŠ¡é˜Ÿåˆ—...');

    for (const [name, queue] of Object.entries(this.queues)) {
      try {
        await queue.close();
        console.log(`âœ… é˜Ÿåˆ— ${name} å·²å…³é—­`);
      } catch (error) {
        console.error(`âŒ å…³é—­é˜Ÿåˆ— ${name} å¤±è´¥:`, error);
      }
    }

    this.initialized = false;
    console.log('âœ… æ‰€æœ‰é˜Ÿåˆ—å·²å…³é—­');
  }
}

module.exports = QueueManager;
